{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f877573",
   "metadata": {},
   "source": [
    "Experiment, when there are calculated some statistics for Adult and German statlog datasets, for comparision to gradient optimization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321e8864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "from rf_counterfactuals import RandomForestExplainer, visualize, evaluate_counterfactual\n",
    "from rf_counterfactuals.single_cf_costs_functions import heterogeneous_euclidean_overlap_metric, unmatched_components_distance\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "DATASET_PATH = \"./datasets/\"\n",
    "\n",
    "N_ESTIMATORS = 100\n",
    "MAX_DEPTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495cfa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'German'\n",
    "\n",
    "COLUMNS = ['checking_account', 'duration', 'credit_history', 'purpose', 'credit_amount', 'saving_account', 'present_employement',\n",
    "          'installment_rate', 'personal_status', 'other_debtors', 'present_residence', 'property', 'age', 'installment_plans',\n",
    "          'housing', 'existing_credits_number', 'job', 'people_to_provide_maintenance', 'has_telephone', 'foreign', 'risk']\n",
    "\n",
    "german_dataset = pd.read_csv(os.path.join(DATASET_PATH, \"german_data.csv\"), sep=' ', names=COLUMNS)\n",
    "\n",
    "class_feature = \"risk\"\n",
    "CATEGORICAL_FEATURES = [0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 18, 19]\n",
    "FROZEN_FEATURES = [2]\n",
    "LEFT_FROZEN_FEATURES = [12]\n",
    "to_encode = [c for no, c in enumerate(COLUMNS) if no in CATEGORICAL_FEATURES]\n",
    "\n",
    "d = defaultdict(preprocessing.LabelEncoder)\n",
    "\n",
    "german_dataset[to_encode] = german_dataset[to_encode].apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "X = german_dataset.loc[:, german_dataset.columns!=class_feature]\n",
    "y = german_dataset[class_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ffc3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_NAME = 'Adult'\n",
    "\n",
    "# adult_dataset = pd.read_csv(os.path.join(DATASET_PATH, \"adult.csv\"))\n",
    "# adult_dataset = adult_dataset.loc[:, adult_dataset.columns!='fnlwgt']\n",
    "\n",
    "# class_feature = \"income\"\n",
    "# feature_names = [c for c in adult_dataset.columns if c != class_feature]\n",
    "# CATEGORICAL_FEATURES = [1, 2, 4, 5, 6, 7, 8, 12]\n",
    "# FROZEN_FEATURES = [7, 8]\n",
    "# LEFT_FROZEN_FEATURES = [0]\n",
    "# to_encode = [c for no, c in enumerate(feature_names) if no in CATEGORICAL_FEATURES]\n",
    "\n",
    "# d = defaultdict(preprocessing.LabelEncoder)\n",
    "\n",
    "# adult_dataset[to_encode] = adult_dataset[to_encode].apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "# X = adult_dataset.loc[:, adult_dataset.columns!=class_feature]\n",
    "# y = adult_dataset[class_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d469670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SPLITS = 10\n",
    "EPSILON = [0.01]\n",
    "CONFIGURATION = ['no_constraints', 'only_categorical', 'cat+mono', 'cat+freeze']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=SPLITS, shuffle=True, random_state=1000)\n",
    "\n",
    "CLASSES = y.unique()\n",
    "\n",
    "scores = defaultdict(list)\n",
    "\n",
    "accuracy = []\n",
    "split = 0\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(split+1, \"/\", SPLITS)\n",
    "    split += 1\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=N_ESTIMATORS, max_depth=MAX_DEPTH)\n",
    "    rf.fit(X_train, y_train)\n",
    "    accuracy.append(accuracy_score(y_test, rf.predict(X_test)))\n",
    "    \n",
    "#     print(accuracy)\n",
    "\n",
    "    X_test_sample = X_test.sample(100)\n",
    "    y_test_sample = rf.predict(X_test_sample)\n",
    "\n",
    "    X_test_sample_0 = X_test_sample[y_test_sample==CLASSES[0]]\n",
    "    X_test_sample_1 = X_test_sample[y_test_sample==CLASSES[1]]\n",
    "    \n",
    "#     start_time = time.time()\n",
    "    \n",
    "#     closest_neighbors_cat_0 = knn_cat_0.kneighbors(X_test_sample_0.values, return_distance=False)[:, 1]\n",
    "#     closest_neighbors_cat_1 = knn_cat_1.kneighbors(X_test_sample_1.values, return_distance=False)[:, 1]\n",
    "    \n",
    "#     closest_neighbors_no_cat_0 = knn_no_cat_0.kneighbors(X_test_sample_0.values, return_distance=False)[:, 1]\n",
    "#     closest_neighbors_no_cat_1 = knn_no_cat_1.kneighbors(X_test_sample_1.values, return_distance=False)[:, 1]\n",
    "    \n",
    "#     X_0_cat_closest = X_0.iloc[closest_neighbors_cat_0]\n",
    "#     X_1_cat_closest = X_1.iloc[closest_neighbors_cat_1]\n",
    "    \n",
    "#     X_0_no_cat_closest = X_0.iloc[closest_neighbors_no_cat_0]\n",
    "#     X_1_no_cat_closest = X_1.iloc[closest_neighbors_no_cat_1]\n",
    "    \n",
    "#     print(time.time() - start_time, \"s\")\n",
    "#     print(len(X_test_sample_0), len(X_test_sample_1))\n",
    "\n",
    "    for eps in EPSILON:\n",
    "        for conf in CONFIGURATION:\n",
    "            if conf == 'no_constraints':\n",
    "                categorical_features = []\n",
    "                left_frozen_features = []\n",
    "                frozen_features = []\n",
    "            elif conf == 'only_categorical':\n",
    "                categorical_features = CATEGORICAL_FEATURES\n",
    "                left_frozen_features = []\n",
    "                frozen_features = []\n",
    "            elif conf == 'cat+mono':\n",
    "                categorical_features = CATEGORICAL_FEATURES\n",
    "                frozen_features = []\n",
    "                left_frozen_features = LEFT_FROZEN_FEATURES\n",
    "            elif conf == 'cat+freeze':\n",
    "                categorical_features = CATEGORICAL_FEATURES\n",
    "                frozen_features = FROZEN_FEATURES\n",
    "                left_frozen_features = LEFT_FROZEN_FEATURES\n",
    "            print(eps, conf)\n",
    "            \n",
    "            \n",
    "            rfe = RandomForestExplainer(rf, X_train, y_train, categorical_features=categorical_features, \n",
    "                                        left_frozen_features=left_frozen_features, frozen_features=frozen_features)\n",
    "\n",
    "            cfs0 = rfe.explain_with_single_metric(X_test_sample_0, CLASSES[1], eps=eps, metric='hoem', k=1, limit=1)\n",
    "            cfs1 = rfe.explain_with_single_metric(X_test_sample_1, CLASSES[0], eps=eps, metric='hoem', k=1, limit=1)\n",
    "            \n",
    "#             if conf == 'no_constraints':\n",
    "#                 cfs0_closest_neighbour = rfe.explain_with_single_metric(X_0_no_cat_closest, '>50K', eps=eps, metric='hoem', k=1, limit=1)\n",
    "#                 cfs1_closest_neighbour = rfe.explain_with_single_metric(X_1_no_cat_closest, '<=50K', eps=eps, metric='hoem', k=1, limit=1)\n",
    "#             else:\n",
    "#                 cfs0_closest_neighbour = rfe.explain_with_single_metric(X_0_cat_closest, '>50K', eps=eps, metric='hoem', k=1, limit=1)\n",
    "#                 cfs1_closest_neighbour = rfe.explain_with_single_metric(X_1_cat_closest, '<=50K', eps=eps, metric='hoem', k=1, limit=1)\n",
    "                \n",
    "                \n",
    "            cfs_count = 0\n",
    "            delta_count = 0\n",
    "            s = []\n",
    "            for i in range(len(cfs0)):\n",
    "                if len(cfs0[i]) == 0:\n",
    "                    continue\n",
    "                cfs_count += 1\n",
    "                proximity = heterogeneous_euclidean_overlap_metric(X_test_sample_0.iloc[i], cfs0[i].iloc[0],\n",
    "                                                                  rfe.X_train_stats['range'], rfe.categorical_features,\n",
    "                                                                  rfe.non_categorical_features)\n",
    "\n",
    "                sparsity = unmatched_components_distance(X_test_sample_0.iloc[i], cfs0[i].iloc[0])\n",
    "                \n",
    "                delta = rf.predict(cfs0[i].iloc[0].to_frame(0).T) == CLASSES[1]\n",
    "                \n",
    "                beta = 0.0\n",
    "#                 beta = heterogeneous_euclidean_overlap_metric(cfs0[i].iloc[0], cfs0_closest_neighbour[i].iloc[0],\n",
    "#                                                                   rfe.X_train_stats['range'], rfe.categorical_features,\n",
    "#                                                                   rfe.non_categorical_features)\n",
    "                \n",
    "                \n",
    "                s.append([proximity, beta, sparsity, int(delta[0])])\n",
    "\n",
    "            for i in range(len(cfs1)):\n",
    "                if len(cfs1[i]) == 0:\n",
    "                    continue\n",
    "                cfs_count += 1\n",
    "                proximity = heterogeneous_euclidean_overlap_metric(X_test_sample_1.iloc[i], cfs1[i].iloc[0],\n",
    "                                                                  rfe.X_train_stats['range'], rfe.categorical_features,\n",
    "                                                                  rfe.non_categorical_features)\n",
    "                sparsity = unmatched_components_distance(X_test_sample_1.iloc[i], cfs1[i].iloc[0])\n",
    "                delta = rf.predict(cfs1[i].iloc[0].to_frame(0).T) == CLASSES[0]\n",
    "                \n",
    "                beta = 0.0\n",
    "#                 beta = heterogeneous_euclidean_overlap_metric(cfs1[i].iloc[0], cfs1_closest_neighbour[i].iloc[0],\n",
    "#                                                                   rfe.X_train_stats['range'], rfe.categorical_features,\n",
    "#                                                                   rfe.non_categorical_features)\n",
    "                \n",
    "                s.append([proximity, beta, sparsity, int(delta[0])])\n",
    "\n",
    "            scores[f'{eps}_{conf}'].append(np.hstack([np.mean(np.array(s), axis=0), cfs_count/len(X_test_sample)]))\n",
    "\n",
    "\n",
    "accuracy_mean, accuracy_std = np.mean(accuracy), np.std(accuracy)\n",
    "accuracy_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d930ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mean = {k: np.mean(scores[k], axis=0) for k, v in scores.items()}\n",
    "scores_std = {k: np.std(scores[k], axis=0) for k, v in scores.items()}\n",
    "\n",
    "pd.DataFrame.from_dict(scores_mean, orient='index', columns=['proximity', 'beta', 'sparsity', 'delta', 'found cfs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e5f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_text = [\"brak\", \"tylko atr. nominalne\", \"nominalne + monotonniczność\", \"nominalne + zamrożone\"]\n",
    "\n",
    "print(\"\\\\multirow{4}{*}{FT} \")\n",
    "for no, k in enumerate(scores_mean.keys()):\n",
    "    print(f\"& {constraints_text[no]} & {scores_mean[k][0]:1.4f} & {scores_mean[k][1]:1.4f} & {scores_mean[k][2]:1.4f} & {scores_mean[k][3]:1.4f}\\\\\\\\\")\n",
    "    print(\"\\\\hhline{~-----}\")\n",
    "print(\"\\\\hline\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630b522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints_text = [\"brak\", \"tylko atr. nominalne\", \"nominalne + monotonniczność\", \"nominalne + zamrożone\"]\n",
    "\n",
    "print(\"\\\\multirow{4}{*}{FT} \")\n",
    "for no, k in enumerate(scores_mean.keys()):\n",
    "    print(f\"& {constraints_text[no]} & {scores_mean[k][0]:1.4f}({scores_std[k][0]:1.4f}) & {scores_mean[k][1]:1.4f}({scores_std[k][1]:1.4f}) & {scores_mean[k][2]:1.4f}({scores_std[k][2]:1.4f}) & {scores_mean[k][3]:1.4f}({scores_std[k][3]:1.4f})\\\\\\\\\")\n",
    "    print(\"\\\\hhline{~-----}\")\n",
    "print(\"\\\\hline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ef1e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rf-counterfactuals-venv",
   "language": "python",
   "name": "rf-counterfactuals-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
