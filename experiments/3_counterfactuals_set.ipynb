{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c73d9f95",
   "metadata": {},
   "source": [
    "Here we compare multicriterial selection for counterfactuals with single ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20444e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "from rf_counterfactuals import RandomForestExplainer, visualize, evaluate_counterfactual, evaluate_counterfactual_set\n",
    "from rf_counterfactuals.single_cf_costs_functions import heterogeneous_euclidean_overlap_metric, unmatched_components_distance\n",
    "from rf_counterfactuals.multi_cf_costs_functions import diversity\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, pairwise_distances\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "DATASET_PATH = \"./datasets/\"\n",
    "\n",
    "N_JOBS = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea9017",
   "metadata": {},
   "source": [
    "# Comment one of two cells below to choose a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_dataset = pd.read_csv(os.path.join(DATASET_PATH, \"adult.csv\"))\n",
    "\n",
    "class_feature = \"income\"\n",
    "feature_names = [c for c in adult_dataset.columns if c != class_feature]\n",
    "categorical_features = [1, 3, 5, 6, 7, 8, 9, 13]\n",
    "to_encode = [c for no, c in enumerate(feature_names) if no in categorical_features]\n",
    "\n",
    "d = defaultdict(preprocessing.LabelEncoder)\n",
    "\n",
    "adult_dataset[to_encode] = adult_dataset[to_encode].apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "X = adult_dataset.loc[:, adult_dataset.columns!=class_feature]\n",
    "y = adult_dataset[class_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42398e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS = ['checking_account', 'duration', 'credit_history', 'purpose', 'credit_amount', 'saving_account', 'present_employement',\n",
    "#           'installment_rate', 'personal_status', 'other_debtors', 'present_residence', 'property', 'age', 'installment_plans',\n",
    "#           'housing', 'existing_credits_number', 'job', 'people_to_provide_maintenance', 'has_telephone', 'foreign', 'risk']\n",
    "\n",
    "# german_dataset = pd.read_csv(os.path.join(DATASET_PATH, \"german_data.csv\"), sep=' ', names=COLUMNS)\n",
    "\n",
    "# class_feature = \"risk\"\n",
    "# categorical_features = [0, 2, 3, 5, 6, 8, 9, 11, 13, 14, 16, 18, 19]\n",
    "# to_encode = [c for no, c in enumerate(COLUMNS) if no in categorical_features]\n",
    "\n",
    "# d = defaultdict(preprocessing.LabelEncoder)\n",
    "\n",
    "# german_dataset[to_encode] = german_dataset[to_encode].apply(lambda x: d[x.name].fit_transform(x))\n",
    "\n",
    "# X = german_dataset.loc[:, german_dataset.columns!=class_feature]\n",
    "# y = german_dataset[class_feature]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e55224",
   "metadata": {},
   "source": [
    "# Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb8ea3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "\n",
    "def calc_metrics(feature_range, cat, non_cat, X_primes, X):\n",
    "    mean_hoem = np.mean([heterogeneous_euclidean_overlap_metric(X.values, X_prime.values, rfe.X_train_stats['range'],\n",
    "                                                                  rfe.categorical_features,\n",
    "                                                                  rfe.non_categorical_features) for _, X_prime in X_primes.iterrows()])\n",
    "    \n",
    "    d = diversity(X_primes, feature_range, cat, non_cat)\n",
    "    return [mean_hoem, d]\n",
    "   \n",
    "\n",
    "CLASSES = y.unique()\n",
    "\n",
    "SPLITS = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=SPLITS, shuffle=True, random_state=1000)\n",
    "eps = 0.1\n",
    "categorical_features = [1, 3, 5, 6, 7, 8, 9, 13]\n",
    "frozen_features = [8, 9]\n",
    "left_frozen_features = [0]\n",
    "\n",
    "scores = defaultdict(list)\n",
    "\n",
    "accuracy = []\n",
    "split = 0\n",
    "\n",
    "total_found = defaultdict(list)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    start_time = time.time()\n",
    "    print(split+1, \"/\", SPLITS)\n",
    "    split += 1\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "    rf.fit(X_train, y_train)\n",
    "    accuracy.append(accuracy_score(y_test, rf.predict(X_test)))\n",
    "    \n",
    "#     X_test = X_test.sample(100)\n",
    "    \n",
    "    y_hat = rf.predict(X_test)\n",
    "    X_test_0 = X_test[y_hat==CLASSES[0]]\n",
    "    X_test_1 = X_test[y_hat==CLASSES[1]]\n",
    "\n",
    "    \n",
    "    rfe = RandomForestExplainer(rf, X_train, y_train, categorical_features=categorical_features, \n",
    "                                        left_frozen_features=left_frozen_features, frozen_features=frozen_features)\n",
    "    \n",
    "    \n",
    "    cfs0 = rfe.explain_with_multiple_metrics(X_test_0, CLASSES[1], eps=eps, k=5, metrics=('hoem', 'unmatched_components'), n_jobs=N_JOBS)\n",
    "    cfs1 = rfe.explain_with_multiple_metrics(X_test_1, CLASSES[0], eps=eps, k=5, metrics=('hoem', 'unmatched_components'), n_jobs=N_JOBS)\n",
    "\n",
    "    found_0 = sum([1 for i in range(len(cfs0)) if len(cfs0[i]) >= 2])\n",
    "    found_1 = sum([1 for i in range(len(cfs1)) if len(cfs1[i]) >= 2])\n",
    "    \n",
    "    total_found['0'] += [found_0, len(cfs0)]\n",
    "    total_found['1'] += [found_1, len(cfs1)]\n",
    "    \n",
    "    print(f\"found_0: {found_0} / {X_test_0.shape[0]}\")\n",
    "    print(f\"found_1: {found_1} / {X_test_1.shape[0]}\")\n",
    "    \n",
    "    \n",
    "    rfe = RandomForestExplainer(rf, X_train, y_train, categorical_features=categorical_features, \n",
    "                                        left_frozen_features=left_frozen_features, frozen_features=frozen_features)\n",
    "    \n",
    "    cfs0_single_hoem = rfe.explain_with_single_metric(X_test_0, CLASSES[1], eps=eps, metric='hoem', k=5, limit=None, n_jobs=N_JOBS)\n",
    "    cfs1_single_hoem = rfe.explain_with_single_metric(X_test_1, CLASSES[0], eps=eps, metric='hoem', k=5, limit=None, n_jobs=N_JOBS)\n",
    "    \n",
    "    rfe = RandomForestExplainer(rf, X_train, y_train, categorical_features=categorical_features, \n",
    "                                        left_frozen_features=left_frozen_features, frozen_features=frozen_features)\n",
    "    \n",
    "    cfs0_single_ucr = rfe.explain_with_single_metric(X_test_0, CLASSES[1], eps=eps, metric='unmatched_components', k=5, limit=None, n_jobs=N_JOBS)\n",
    "    cfs1_single_ucr = rfe.explain_with_single_metric(X_test_1, CLASSES[0], eps=eps, metric='unmatched_components', k=5, limit=None, n_jobs=N_JOBS)\n",
    "    \n",
    "#     cfs0_single_im = rfe.explain_with_single_metric(X_test_0, CLASSES[1], eps=eps, metric='implausibility_single', k=5, limit=None, n_jobs=N_JOBS)\n",
    "#     cfs1_single_im = rfe.explain_with_single_metric(X_test_1, CLASSES[0], eps=eps, metric='implausibility_single', k=5, limit=None, n_jobs=N_JOBS)\n",
    "    \n",
    "\n",
    "    results = Parallel(n_jobs=N_JOBS)(delayed(partial(calc_metrics, rfe.X_train_stats['range'],\n",
    "                                                     rfe.categorical_features, rfe.non_categorical_features)\n",
    "                                             )(cfs0[i], X_test_0.iloc[i]) for i in range(len(cfs0)) if len(cfs0[i]) >= 2)\n",
    "    scores['multi0'].append(results)\n",
    "    \n",
    "    results = Parallel(n_jobs=N_JOBS)(delayed(partial(calc_metrics, rfe.X_train_stats['range'],\n",
    "                                                     rfe.categorical_features, rfe.non_categorical_features)\n",
    "                                             )(cfs1[i], X_test_1.iloc[i]) for i in range(len(cfs1)) if len(cfs1[i]) >= 2)\n",
    "    scores['multi1'].append(results)\n",
    "\n",
    "    \n",
    "    results = Parallel(n_jobs=N_JOBS)(delayed(partial(calc_metrics, rfe.X_train_stats['range'],\n",
    "                                                     rfe.categorical_features, rfe.non_categorical_features)\n",
    "                                             )(cfs0_single_hoem[i].iloc[:len(cfs0[i])], X_test_0.iloc[i]) for i in range(len(cfs0)) if len(cfs0[i]) >= 2)\n",
    "    scores['hoem0'].append(results)\n",
    "\n",
    "    results = Parallel(n_jobs=N_JOBS)(delayed(partial(calc_metrics, rfe.X_train_stats['range'],\n",
    "                                                     rfe.categorical_features, rfe.non_categorical_features)\n",
    "                                             )(cfs1_single_hoem[i].iloc[:len(cfs1[i])], X_test_1.iloc[i]) for i in range(len(cfs1)) if len(cfs1[i]) >= 2)\n",
    "    scores['hoem1'].append(results)\n",
    "    \n",
    "    results = Parallel(n_jobs=N_JOBS)(delayed(partial(calc_metrics, rfe.X_train_stats['range'],\n",
    "                                                     rfe.categorical_features, rfe.non_categorical_features)\n",
    "                                             )(cfs0_single_ucr[i].iloc[:len(cfs0[i])], X_test_0.iloc[i]) for i in range(len(cfs0)) if len(cfs0[i]) >= 2)\n",
    "    scores['uc0'].append(results)\n",
    "    \n",
    "    results = Parallel(n_jobs=N_JOBS)(delayed(partial(calc_metrics, rfe.X_train_stats['range'],\n",
    "                                                     rfe.categorical_features, rfe.non_categorical_features)\n",
    "                                             )(cfs1_single_ucr[i].iloc[:len(cfs1[i])], X_test_1.iloc[i]) for i in range(len(cfs1)) if len(cfs1[i]) >= 2)\n",
    "    scores['uc1'].append(results)\n",
    "    \n",
    "\n",
    "    print(\"Split time: \", time.time() - start_time, \"s\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "accuracy_mean, accuracy_std = np.mean(accuracy), np.std(accuracy)\n",
    "accuracy_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568f1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(total_found['0'][1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(total_found['1'][1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0685dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "scores2 = {}\n",
    "\n",
    "for key, value in scores.items():\n",
    "    score = np.array(list(itertools.chain.from_iterable(value)))\n",
    "#     print(score)\n",
    "    \n",
    "    scores2[key] = score\n",
    "\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a569b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores3 = {'multi': np.vstack([scores2['multi0'], scores2['multi1']]),\n",
    "          'hoem': np.vstack([scores2['hoem0'], scores2['hoem1']]),\n",
    "          'uc': np.vstack([scores2['uc0'], scores2['uc1']])\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cfd153",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_found_num = sum(total_found['0'][::2]) + sum(total_found['1'][::2])\n",
    "total_found_denum = sum(total_found['0'][1::2]) + sum(total_found['1'][1::2])\n",
    "\n",
    "total_found_num, total_found_denum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3757993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLABELS = [f\"pareto {CLASSES[0]} -> {CLASSES[1]}\", f\"pareto {CLASSES[0]} -> {CLASSES[1]}\", f\"hoem {CLASSES[0]} -> {CLASSES[1]}\",\n",
    "#            f\"hoem {CLASSES[0]} -> {CLASSES[1]}\", f\"unmatched_components {CLASSES[0]} -> {CLASSES[1]}\", f\"unmatched_components {CLASSES[0]} -> {CLASSES[1]}\"]\n",
    "\n",
    "XLABELS = [f\"pareto_optimal (hoem, u_c)\", f\"hoem\", f\"unmatched_components\"]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "y_pos = np.arange(len(scores3.keys()))\n",
    "means = np.array([np.mean(s, axis=0) for s in scores3.values()])\n",
    "stds = np.array([np.std(s, axis=0) for s in scores3.values()])\n",
    "\n",
    "width=0.45\n",
    "\n",
    "\n",
    "plt.barh(y_pos, means[:, 0], width, xerr=stds[:, 0], label='mean_hoem (lower better)')\n",
    "plt.barh(y_pos+width, means[:, 1], width, xerr=stds[:, 1], label='diversity (higher better)')\n",
    "\n",
    "ax.set_yticks(y_pos, labels=XLABELS)\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('Value')\n",
    "ax.set_ylabel(\"Metric\")\n",
    "ax.set_title(f\"Adult dataset, 10-fold-cv. Random 100 samples from test data. Evaluation of set with counterfactuals\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7197a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for no, metric in enumerate(XLABELS):\n",
    "    print(f\"{metric} & {means[no, 0]:1.3f}({stds[no, 0]:1.3f}) & {means[no, 1]:1.3f}({stds[no, 1]:1.3f}) \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cc8002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rf-counterfactuals-venv",
   "language": "python",
   "name": "rf-counterfactuals-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
